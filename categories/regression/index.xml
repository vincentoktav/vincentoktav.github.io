<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>regression | Vincent Oktavianus</title>
    <link>/categories/regression/</link>
      <atom:link href="/categories/regression/index.xml" rel="self" type="application/rss+xml" />
    <description>regression</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© Vincent Oktavianus, 2020</copyright><lastBuildDate>Sat, 06 Jun 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>regression</title>
      <link>/categories/regression/</link>
    </image>
    
    <item>
      <title>Predicting Airbnb house prices</title>
      <link>/post/airbnb-house-regression/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/airbnb-house-regression/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;load-library&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;em&gt;Load Library&lt;/em&gt;&lt;/h1&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;abstract&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Abstract&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Most individuals who sleep at their destination would need a “home away from home.” Businesses have always taken care of that. But Airbnb gave the market a fresh and exciting twist. variety of learning techniques were explored and validated, but ultimately the predictive power of the models appears to be limited by the available data. Additional data collection is recommended.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;When you are away from home for business or pleasure, it is essential that you have a place to relax and rest. &lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The days of calling hotels and comparing rates over the phone are gone for a long time, and using applications to locate, compare, and book hotels or private residences is the way of the present. &lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Airbnb, one of the many options that allow you to rent a personal home or a room in someone else’s house, offering an incredible experience ranging from traditional hotels to luxury mansions. You can read other guest reviews within the app, interact safely with estate owners, and much more. Moreover, you can even list your space and become hospitality entrepreneurs.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; As Airbnb popularity rises among the public, many including the company itself use the data to find out more about hosts, geographical availability, necessary metrics to make predictions and draw conclusions. Many variables can affect the rental price of an Airbnb listing. However, is it beneficial to predict a rental price? And will be it enough to use only a limited amount of numerical and categorical metrics such as the data provided via Kaggle to estimate the price of rentals?&lt;/p&gt;
&lt;p&gt;Statistical learning techniques were applied to several listings from Airbnb in New York during 2019. All variables including name, location, room type, and the number of reviews were used to predict the price of rentals. The results indicate that this prediction is almost impossible to make due to a large amount of error. The importance of predicting the price and statistical limitations suggest the need for further investigation.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;methods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Methods&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;The data was accessed via Kaggle. &lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; It contains information on Airbnb listings in New York, NY during 2019 including price, rental attributes, and location. For the purposes of this analysis, the data was restricted to short term (one week or less) rentals in Brooklyn that rent for less than $1000 a night. (Additionally, only rentals that have been reviewed are included.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;airbnb = read_csv(file = &amp;quot;data/AB_NYC_2019.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;brooklyn = airbnb %&amp;gt;% 
  filter(minimum_nights &amp;lt;= 7) %&amp;gt;%
  filter(neighbourhood_group == &amp;quot;Brooklyn&amp;quot;) %&amp;gt;% 
  filter(number_of_reviews &amp;gt; 0) %&amp;gt;%
  filter(price &amp;gt; 0, price &amp;lt; 1000) %&amp;gt;% 
  na.omit() %&amp;gt;% 
  select(latitude, longitude, room_type, price, minimum_nights, number_of_reviews, 
         reviews_per_month, calculated_host_listings_count, availability_365) %&amp;gt;% 
  mutate(room_type = as.factor(room_type))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42)
# test-train split
bk_tst_trn_split = initial_split(brooklyn, prop = 0.80)
bk_trn = training(bk_tst_trn_split)
bk_tst = testing(bk_tst_trn_split)
# estimation-validation split
bk_est_val_split = initial_split(bk_trn, prop = 0.80)
bk_est = training(bk_est_val_split)
bk_val = testing(bk_est_val_split)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modeling&lt;/h2&gt;
&lt;p&gt;In order to predict the price of rentals, three modeling techniques were considered: linear models, k-nearest neighbors models, and decision tree models.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linear models with and without log transformed responses were considered. Various subsets of predictors, with and without interaction terms were explored.&lt;/li&gt;
&lt;li&gt;k-nearest neighbors models were trained using all available predictor variables. The choice of k was chosen using a validation set.&lt;/li&gt;
&lt;li&gt;Decision tree models were trained using all available predictors. The choice of the complexity parameter was chosen using a validation set.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1 = lm(price ~ ., data = bk_est)
fit2 = step(fit1, direction = &amp;quot;backward&amp;quot;)
fit3 = step(lm(price ~ . ^ 2, data = bk_est), direction = &amp;quot;backward&amp;quot;)
fit4 = lm(log(price) ~ ., data = bk_est)
fit5 = step(lm(log(price) ~ ., data = bk_est), direction = &amp;quot;backward&amp;quot;)
fit6 = step(lm(log(price) ~ . ^ 2, data = bk_est), direction = &amp;quot;backward&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;k = 1:100
knn_mods = map(k, ~knnreg(price ~ ., data = bk_est, k = .x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cp = c(1.000, 0.100, 0.010, 0.001, 0)
tree_mods = map(cp, ~rpart(price ~ ., data = bk_est, cp = .x))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;To evaluate the ability to predict rental prices, the data was split into estimation, validation, and testing sets. Error metrics and graphics are reported using the validation data in the Results section.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;calc_rmse = function(actual, predicted) {
  sqrt(mean( (actual - predicted) ^ 2) )
}

calc_rmse_model = function(model, data, response) {
  actual = data[[response]]
  predicted = predict(model, data)
  sqrt(mean((actual - predicted) ^ 2))
}

calc_rmse_log_model = function(model, data, response) {
  actual = data[[response]]
  predicted = exp(predict(model, data))
  sqrt(mean((actual - predicted) ^ 2))
}&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rmse_lm1 = calc_rmse(actual = bk_val$price, predicted = predict(fit1, bk_val))
rmse_lm2 = calc_rmse(actual = bk_val$price, predicted = predict(fit2, bk_val))
rmse_lm3 = calc_rmse(actual = bk_val$price, predicted = predict(fit3, bk_val))
rmse_lm4 = calc_rmse_log_model(model = fit4, data = bk_val, response = &amp;quot;price&amp;quot;)
rmse_lm5 = calc_rmse_log_model(model = fit5, data = bk_val, response = &amp;quot;price&amp;quot;)
rmse_lm6 = calc_rmse_log_model(model = fit6, data = bk_val, response = &amp;quot;price&amp;quot;)
lm_val_rmse = c(rmse_lm1, rmse_lm2, rmse_lm3)
log_lm_rmse = c(rmse_lm4, rmse_lm5, rmse_lm6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knn_preds = map(knn_mods, predict, bk_val)
knn_val_rmse = map_dbl(knn_preds, calc_rmse, actual = bk_val$price)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tree_preds = map(tree_mods, predict, bk_val)
tree_val_rmse = map_dbl(tree_preds, calc_rmse, actual = bk_val$price)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(
  &amp;quot;Model&amp;quot; = c(&amp;quot;Linear&amp;quot;, &amp;quot;Log Linear&amp;quot;, &amp;quot;KNN&amp;quot;, &amp;quot;Decision Tree&amp;quot;),
  &amp;quot;Tuning&amp;quot; = c(&amp;quot;Subset of Interactions&amp;quot;, &amp;quot;Subset of Interactions&amp;quot;, &amp;quot;k = 44&amp;quot;, &amp;quot;cp = 0.001&amp;quot;),
  &amp;quot;Validation RMSE&amp;quot; = c(lm_val_rmse[which.min(lm_val_rmse)],
                        log_lm_rmse[which.min(log_lm_rmse)],
                        knn_val_rmse[which.min(knn_val_rmse)],
                        tree_val_rmse[which.min(tree_val_rmse)])
) %&amp;gt;% 
  kable(digits = 2) %&amp;gt;% 
  kable_styling(&amp;quot;striped&amp;quot;, full_width = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Model
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Tuning
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Validation RMSE
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Linear
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Subset of Interactions
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66.29
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Log Linear
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Subset of Interactions
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66.62
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
KNN
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
k = 44
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
81.40
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Decision Tree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
cp = 0.001
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69.02
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow = c(1, 3))

axis_limits = c(0, 900)

plot(predict(fit3, bk_val), bk_val$price,
     xlim = axis_limits, ylim = axis_limits, pch = 19, col = &amp;quot;red&amp;quot;,
     xlab = &amp;quot;Predicted&amp;quot;, ylab = &amp;quot;Actual&amp;quot;, 
     main = &amp;quot;Model: Linear | Data: Validation&amp;quot;)
abline(a = 0, b = 1, col = &amp;quot;grey&amp;quot;)
grid()

plot(predict(knn_mods[[44]], bk_val), bk_val$price,
     xlim = axis_limits, ylim = axis_limits, pch = 19, col = &amp;quot;lightblue&amp;quot;,
     xlab = &amp;quot;Predicted&amp;quot;, ylab = &amp;quot;Actual&amp;quot;, 
     main = &amp;quot;Model: KNN | Data: Validation&amp;quot;)
abline(a = 0, b = 1, col = &amp;quot;grey&amp;quot;)
grid()

plot(predict(tree_mods[[4]], bk_val), bk_val$price,
     xlim = axis_limits, ylim = axis_limits, pch = 19, col = &amp;quot;green&amp;quot;,
     xlab = &amp;quot;Predicted&amp;quot;, ylab = &amp;quot;Actual&amp;quot;, 
     main = &amp;quot;Model: Tree | Data: Validation&amp;quot;)
abline(a = 0, b = 1, col = &amp;quot;grey&amp;quot;)
grid()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/AirBnB-pricing-predict/index_files/figure-html/graphical-results-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;discussion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_mod = step(lm(price ~ . ^ 2, data = bk_trn), direction = &amp;quot;backward&amp;quot;)
tst_rmse = calc_rmse(actual = bk_tst$price, predicted = predict(lm_mod, bk_tst))
tst_rmse&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given the results of assessing model performance on the validation data, the linear model that selects from all available predictors, as well as all two-way interactions using backwards selection and AIC appears to be a reasonable choice. Using the test data, we obtain a RMSE of 72.626 dollars. While the range of prices seen in this data, ranging from roughly 0 to 10,000 dollars, with most observations greater than 50 dollars and less than 200 dollars (from the box plot of room_type versus price), this seems to suggest our model is performing badly at the prediction task.&lt;/p&gt;
&lt;p&gt;The provided dataset may be the limiting factor in this analysis. Even with limited domain knowledge, it should be rather clear that the attributes of the rentals are extremely lacking. There are many more variables that might be more helpful in predicting rental prices such as house rules, amenities, cancellation policy, number of positive and ne. It turns out that Airbnb actually releases much more information than is re-hosted on Kaggle. We will use the complete data in our next analysis.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;data-dictionary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Dictionary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;latitude&lt;/code&gt; - latitude coordinates of the listing&lt;/li&gt;
&lt;li&gt;&lt;code&gt;longitude&lt;/code&gt; - longitude coordinates of the listing&lt;/li&gt;
&lt;li&gt;&lt;code&gt;room_type&lt;/code&gt; - listing space type&lt;/li&gt;
&lt;li&gt;&lt;code&gt;price&lt;/code&gt; - price in dollars&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minimum_nights&lt;/code&gt; - amount of nights minimum&lt;/li&gt;
&lt;li&gt;&lt;code&gt;number_of_reviews&lt;/code&gt; - number of reviews&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reviews_per_month&lt;/code&gt; - number of reviews per month&lt;/li&gt;
&lt;li&gt;&lt;code&gt;calculated_host_listings_count&lt;/code&gt; - amount of listing per host&lt;/li&gt;
&lt;li&gt;&lt;code&gt;availability_365&lt;/code&gt; - number of days when listing is available for booking&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For additional background on the data, see the data source on Kaggle.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;eda&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;EDA&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_1 = bk_trn %&amp;gt;% 
  ggplot(aes(x = price)) + 
  geom_histogram(bins = 30)

plot_2 = bk_trn %&amp;gt;% 
  ggplot(aes(x = room_type, y = price, colour = price)) + 
  geom_boxplot()

plot_3 = bk_trn %&amp;gt;% 
  ggplot(aes(x = reviews_per_month, y = price)) + 
  geom_point() + geom_smooth(span = 0.3)

gridExtra::grid.arrange(plot_1, plot_2, plot_3, ncol = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/AirBnB-pricing-predict/index_files/figure-html/eda-plots-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bk_trn %&amp;gt;% 
  ggplot(aes(x = longitude, y = latitude, colour = price)) + 
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/AirBnB-pricing-predict/index_files/figure-html/price-map-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.imore.com/best-apps-finding-place-stay&#34;&gt;Best Apps for Finding a Place to Stay&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://press.airbnb.com/about-us/&#34;&gt;About Airbnb&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://muchneeded.com/airbnb-statistics/&#34;&gt;Statistics of Airbnb&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data&#34;&gt;New York City Airbnb Open Data&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Basic Exploratory Data Analysis and Simple Linear Regression in Python</title>
      <link>/post/wine-eda/</link>
      <pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/post/wine-eda/</guid>
      <description>&lt;h1 id=&#34;import-library&#34;&gt;Import Library&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import math
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression

# Visulaization options:
%matplotlib inline
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;read-data&#34;&gt;Read data&lt;/h1&gt;
&lt;h3 id=&#34;data-obtained-from-uci-machine-learning-repository--accessed-via-kaggle-httpswwwkagglecomucimlred-wine-quality-cortez-et-al-2009&#34;&gt;Data obtained from UCI Machine Learning Repository &amp;amp; accessed via Kaggle (&lt;a href=&#34;https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009&#34;&gt;https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009&lt;/a&gt;)&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.read_csv(&amp;quot;redwine.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;fixed acidity&lt;/th&gt;
      &lt;th&gt;volatile acidity&lt;/th&gt;
      &lt;th&gt;citric acid&lt;/th&gt;
      &lt;th&gt;residual sugar&lt;/th&gt;
      &lt;th&gt;chlorides&lt;/th&gt;
      &lt;th&gt;free sulfur dioxide&lt;/th&gt;
      &lt;th&gt;total sulfur dioxide&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
      &lt;th&gt;pH&lt;/th&gt;
      &lt;th&gt;sulphates&lt;/th&gt;
      &lt;th&gt;alcohol&lt;/th&gt;
      &lt;th&gt;quality&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;7.4&lt;/td&gt;
      &lt;td&gt;0.700&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;1.9&lt;/td&gt;
      &lt;td&gt;0.076&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;34.0&lt;/td&gt;
      &lt;td&gt;0.99780&lt;/td&gt;
      &lt;td&gt;3.51&lt;/td&gt;
      &lt;td&gt;0.56&lt;/td&gt;
      &lt;td&gt;9.4&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;7.8&lt;/td&gt;
      &lt;td&gt;0.880&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;2.6&lt;/td&gt;
      &lt;td&gt;0.098&lt;/td&gt;
      &lt;td&gt;25.0&lt;/td&gt;
      &lt;td&gt;67.0&lt;/td&gt;
      &lt;td&gt;0.99680&lt;/td&gt;
      &lt;td&gt;3.20&lt;/td&gt;
      &lt;td&gt;0.68&lt;/td&gt;
      &lt;td&gt;9.8&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;7.8&lt;/td&gt;
      &lt;td&gt;0.760&lt;/td&gt;
      &lt;td&gt;0.04&lt;/td&gt;
      &lt;td&gt;2.3&lt;/td&gt;
      &lt;td&gt;0.092&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;54.0&lt;/td&gt;
      &lt;td&gt;0.99700&lt;/td&gt;
      &lt;td&gt;3.26&lt;/td&gt;
      &lt;td&gt;0.65&lt;/td&gt;
      &lt;td&gt;9.8&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;11.2&lt;/td&gt;
      &lt;td&gt;0.280&lt;/td&gt;
      &lt;td&gt;0.56&lt;/td&gt;
      &lt;td&gt;1.9&lt;/td&gt;
      &lt;td&gt;0.075&lt;/td&gt;
      &lt;td&gt;17.0&lt;/td&gt;
      &lt;td&gt;60.0&lt;/td&gt;
      &lt;td&gt;0.99800&lt;/td&gt;
      &lt;td&gt;3.16&lt;/td&gt;
      &lt;td&gt;0.58&lt;/td&gt;
      &lt;td&gt;9.8&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7.4&lt;/td&gt;
      &lt;td&gt;0.700&lt;/td&gt;
      &lt;td&gt;0.00&lt;/td&gt;
      &lt;td&gt;1.9&lt;/td&gt;
      &lt;td&gt;0.076&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;34.0&lt;/td&gt;
      &lt;td&gt;0.99780&lt;/td&gt;
      &lt;td&gt;3.51&lt;/td&gt;
      &lt;td&gt;0.56&lt;/td&gt;
      &lt;td&gt;9.4&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1594&lt;/td&gt;
      &lt;td&gt;6.2&lt;/td&gt;
      &lt;td&gt;0.600&lt;/td&gt;
      &lt;td&gt;0.08&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;0.090&lt;/td&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;44.0&lt;/td&gt;
      &lt;td&gt;0.99490&lt;/td&gt;
      &lt;td&gt;3.45&lt;/td&gt;
      &lt;td&gt;0.58&lt;/td&gt;
      &lt;td&gt;10.5&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1595&lt;/td&gt;
      &lt;td&gt;5.9&lt;/td&gt;
      &lt;td&gt;0.550&lt;/td&gt;
      &lt;td&gt;0.10&lt;/td&gt;
      &lt;td&gt;2.2&lt;/td&gt;
      &lt;td&gt;0.062&lt;/td&gt;
      &lt;td&gt;39.0&lt;/td&gt;
      &lt;td&gt;51.0&lt;/td&gt;
      &lt;td&gt;0.99512&lt;/td&gt;
      &lt;td&gt;3.52&lt;/td&gt;
      &lt;td&gt;0.76&lt;/td&gt;
      &lt;td&gt;11.2&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1596&lt;/td&gt;
      &lt;td&gt;6.3&lt;/td&gt;
      &lt;td&gt;0.510&lt;/td&gt;
      &lt;td&gt;0.13&lt;/td&gt;
      &lt;td&gt;2.3&lt;/td&gt;
      &lt;td&gt;0.076&lt;/td&gt;
      &lt;td&gt;29.0&lt;/td&gt;
      &lt;td&gt;40.0&lt;/td&gt;
      &lt;td&gt;0.99574&lt;/td&gt;
      &lt;td&gt;3.42&lt;/td&gt;
      &lt;td&gt;0.75&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1597&lt;/td&gt;
      &lt;td&gt;5.9&lt;/td&gt;
      &lt;td&gt;0.645&lt;/td&gt;
      &lt;td&gt;0.12&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;0.075&lt;/td&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;44.0&lt;/td&gt;
      &lt;td&gt;0.99547&lt;/td&gt;
      &lt;td&gt;3.57&lt;/td&gt;
      &lt;td&gt;0.71&lt;/td&gt;
      &lt;td&gt;10.2&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1598&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;0.310&lt;/td&gt;
      &lt;td&gt;0.47&lt;/td&gt;
      &lt;td&gt;3.6&lt;/td&gt;
      &lt;td&gt;0.067&lt;/td&gt;
      &lt;td&gt;18.0&lt;/td&gt;
      &lt;td&gt;42.0&lt;/td&gt;
      &lt;td&gt;0.99549&lt;/td&gt;
      &lt;td&gt;3.39&lt;/td&gt;
      &lt;td&gt;0.66&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;1599 rows × 12 columns&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&#34;data-description&#34;&gt;Data Description&lt;/h2&gt;
&lt;p&gt;Accessed via Kaggle&lt;/p&gt;
&lt;h3 id=&#34;about&#34;&gt;About&lt;/h3&gt;
&lt;p&gt;The dataset is related to red variants of the Portuguese &lt;strong&gt;&amp;ldquo;Vinho Verde&amp;rdquo;&lt;/strong&gt; wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).&lt;/p&gt;
&lt;h3 id=&#34;input-variables-based-on-physicochemical-tests&#34;&gt;Input variables (based on physicochemical tests):&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fixed acidity&lt;/code&gt; : most acids involved with wine or fixed or nonvolatile (do not evaporate readily).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;volatile acidity&lt;/code&gt; : the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;citric acid&lt;/code&gt; : found in small quantities, citric acid can add &amp;lsquo;freshness&amp;rsquo; and flavor to wines.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;residual sugar&lt;/code&gt; : the amount of sugar remaining after fermentation stops, it&amp;rsquo;s rare to find wines with less than 1 gram/liter and wines with greater than 45 grams/liter are considered sweet.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;chlorides&lt;/code&gt; : the amount of salt in the wine.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;free sulfur dioxide&lt;/code&gt; : the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;total sulfur dioxide&lt;/code&gt; : amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;density&lt;/code&gt; : the density of water is close to that of water depending on the percent alcohol and sugar content.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pH&lt;/code&gt; : describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sulphates&lt;/code&gt; : a wine additive which can contribute to sulfur dioxide gas (S02) levels, which acts as an antimicrobial and antioxidant.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;alcohol&lt;/code&gt; : the percent alcohol content of the wine.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;output-variable-based-on-sensory-data&#34;&gt;Output variable (based on sensory data):&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;quality&lt;/code&gt; : score between 0 and 10 given by human wine tasters.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;exploratory-data-analysis-eda&#34;&gt;Exploratory Data Analysis (EDA)&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out dataframe dimension or shape (rows x columns)
df.shape
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(1599, 12)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out information on the data
df.info()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.core.frame.DataFrame&#39;&amp;gt;
RangeIndex: 1599 entries, 0 to 1598
Data columns (total 12 columns):
fixed acidity           1599 non-null float64
volatile acidity        1599 non-null float64
citric acid             1599 non-null float64
residual sugar          1599 non-null float64
chlorides               1599 non-null float64
free sulfur dioxide     1599 non-null float64
total sulfur dioxide    1599 non-null float64
density                 1599 non-null float64
pH                      1599 non-null float64
sulphates               1599 non-null float64
alcohol                 1599 non-null float64
quality                 1599 non-null int64
dtypes: float64(11), int64(1)
memory usage: 150.0 KB
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out summary information about all numeric data columns in your dataset.
df.describe()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;fixed acidity&lt;/th&gt;
      &lt;th&gt;volatile acidity&lt;/th&gt;
      &lt;th&gt;citric acid&lt;/th&gt;
      &lt;th&gt;residual sugar&lt;/th&gt;
      &lt;th&gt;chlorides&lt;/th&gt;
      &lt;th&gt;free sulfur dioxide&lt;/th&gt;
      &lt;th&gt;total sulfur dioxide&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
      &lt;th&gt;pH&lt;/th&gt;
      &lt;th&gt;sulphates&lt;/th&gt;
      &lt;th&gt;alcohol&lt;/th&gt;
      &lt;th&gt;quality&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;count&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
      &lt;td&gt;1599.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mean&lt;/td&gt;
      &lt;td&gt;8.319637&lt;/td&gt;
      &lt;td&gt;0.527821&lt;/td&gt;
      &lt;td&gt;0.270976&lt;/td&gt;
      &lt;td&gt;2.538806&lt;/td&gt;
      &lt;td&gt;0.087467&lt;/td&gt;
      &lt;td&gt;15.874922&lt;/td&gt;
      &lt;td&gt;46.467792&lt;/td&gt;
      &lt;td&gt;0.996747&lt;/td&gt;
      &lt;td&gt;3.311113&lt;/td&gt;
      &lt;td&gt;0.658149&lt;/td&gt;
      &lt;td&gt;10.422983&lt;/td&gt;
      &lt;td&gt;5.636023&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;std&lt;/td&gt;
      &lt;td&gt;1.741096&lt;/td&gt;
      &lt;td&gt;0.179060&lt;/td&gt;
      &lt;td&gt;0.194801&lt;/td&gt;
      &lt;td&gt;1.409928&lt;/td&gt;
      &lt;td&gt;0.047065&lt;/td&gt;
      &lt;td&gt;10.460157&lt;/td&gt;
      &lt;td&gt;32.895324&lt;/td&gt;
      &lt;td&gt;0.001887&lt;/td&gt;
      &lt;td&gt;0.154386&lt;/td&gt;
      &lt;td&gt;0.169507&lt;/td&gt;
      &lt;td&gt;1.065668&lt;/td&gt;
      &lt;td&gt;0.807569&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;min&lt;/td&gt;
      &lt;td&gt;4.600000&lt;/td&gt;
      &lt;td&gt;0.120000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.900000&lt;/td&gt;
      &lt;td&gt;0.012000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;6.000000&lt;/td&gt;
      &lt;td&gt;0.990070&lt;/td&gt;
      &lt;td&gt;2.740000&lt;/td&gt;
      &lt;td&gt;0.330000&lt;/td&gt;
      &lt;td&gt;8.400000&lt;/td&gt;
      &lt;td&gt;3.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25%&lt;/td&gt;
      &lt;td&gt;7.100000&lt;/td&gt;
      &lt;td&gt;0.390000&lt;/td&gt;
      &lt;td&gt;0.090000&lt;/td&gt;
      &lt;td&gt;1.900000&lt;/td&gt;
      &lt;td&gt;0.070000&lt;/td&gt;
      &lt;td&gt;7.000000&lt;/td&gt;
      &lt;td&gt;22.000000&lt;/td&gt;
      &lt;td&gt;0.995600&lt;/td&gt;
      &lt;td&gt;3.210000&lt;/td&gt;
      &lt;td&gt;0.550000&lt;/td&gt;
      &lt;td&gt;9.500000&lt;/td&gt;
      &lt;td&gt;5.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50%&lt;/td&gt;
      &lt;td&gt;7.900000&lt;/td&gt;
      &lt;td&gt;0.520000&lt;/td&gt;
      &lt;td&gt;0.260000&lt;/td&gt;
      &lt;td&gt;2.200000&lt;/td&gt;
      &lt;td&gt;0.079000&lt;/td&gt;
      &lt;td&gt;14.000000&lt;/td&gt;
      &lt;td&gt;38.000000&lt;/td&gt;
      &lt;td&gt;0.996750&lt;/td&gt;
      &lt;td&gt;3.310000&lt;/td&gt;
      &lt;td&gt;0.620000&lt;/td&gt;
      &lt;td&gt;10.200000&lt;/td&gt;
      &lt;td&gt;6.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;75%&lt;/td&gt;
      &lt;td&gt;9.200000&lt;/td&gt;
      &lt;td&gt;0.640000&lt;/td&gt;
      &lt;td&gt;0.420000&lt;/td&gt;
      &lt;td&gt;2.600000&lt;/td&gt;
      &lt;td&gt;0.090000&lt;/td&gt;
      &lt;td&gt;21.000000&lt;/td&gt;
      &lt;td&gt;62.000000&lt;/td&gt;
      &lt;td&gt;0.997835&lt;/td&gt;
      &lt;td&gt;3.400000&lt;/td&gt;
      &lt;td&gt;0.730000&lt;/td&gt;
      &lt;td&gt;11.100000&lt;/td&gt;
      &lt;td&gt;6.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;max&lt;/td&gt;
      &lt;td&gt;15.900000&lt;/td&gt;
      &lt;td&gt;1.580000&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;15.500000&lt;/td&gt;
      &lt;td&gt;0.611000&lt;/td&gt;
      &lt;td&gt;72.000000&lt;/td&gt;
      &lt;td&gt;289.000000&lt;/td&gt;
      &lt;td&gt;1.003690&lt;/td&gt;
      &lt;td&gt;4.010000&lt;/td&gt;
      &lt;td&gt;2.000000&lt;/td&gt;
      &lt;td&gt;14.900000&lt;/td&gt;
      &lt;td&gt;8.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out the distribution on each column (variable) 
df.hist(bins = 50, edgecolor = &#39;b&#39;, grid = False,
                linewidth = 1.0,
                xlabelsize = 8, ylabelsize = 8,  
                figsize = (16, 6), color = &#39;orange&#39;)    
plt.tight_layout(rect = (0, 0, 1.5, 1.5))   
plt.suptitle(&#39;Red Wine Plots&#39;, x = 0.75, y = 1.65, fontsize = 20);  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/image1.png&#34; alt=&#34;This is an image&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out histogram of the quality variable 
df[&#39;quality&#39;].hist(bins = 6, grid = False, color = &#39;red&#39;, edgecolor = &#39;b&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1f4fc438&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/image2.png&#34; alt=&#34;This is an image&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out the correlation matrix (for each column)
df.corr()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;fixed acidity&lt;/th&gt;
      &lt;th&gt;volatile acidity&lt;/th&gt;
      &lt;th&gt;citric acid&lt;/th&gt;
      &lt;th&gt;residual sugar&lt;/th&gt;
      &lt;th&gt;chlorides&lt;/th&gt;
      &lt;th&gt;free sulfur dioxide&lt;/th&gt;
      &lt;th&gt;total sulfur dioxide&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
      &lt;th&gt;pH&lt;/th&gt;
      &lt;th&gt;sulphates&lt;/th&gt;
      &lt;th&gt;alcohol&lt;/th&gt;
      &lt;th&gt;quality&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;fixed acidity&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;-0.256131&lt;/td&gt;
      &lt;td&gt;0.671703&lt;/td&gt;
      &lt;td&gt;0.114777&lt;/td&gt;
      &lt;td&gt;0.093705&lt;/td&gt;
      &lt;td&gt;-0.153794&lt;/td&gt;
      &lt;td&gt;-0.113181&lt;/td&gt;
      &lt;td&gt;0.668047&lt;/td&gt;
      &lt;td&gt;-0.682978&lt;/td&gt;
      &lt;td&gt;0.183006&lt;/td&gt;
      &lt;td&gt;-0.061668&lt;/td&gt;
      &lt;td&gt;0.124052&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;volatile acidity&lt;/td&gt;
      &lt;td&gt;-0.256131&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;-0.552496&lt;/td&gt;
      &lt;td&gt;0.001918&lt;/td&gt;
      &lt;td&gt;0.061298&lt;/td&gt;
      &lt;td&gt;-0.010504&lt;/td&gt;
      &lt;td&gt;0.076470&lt;/td&gt;
      &lt;td&gt;0.022026&lt;/td&gt;
      &lt;td&gt;0.234937&lt;/td&gt;
      &lt;td&gt;-0.260987&lt;/td&gt;
      &lt;td&gt;-0.202288&lt;/td&gt;
      &lt;td&gt;-0.390558&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;citric acid&lt;/td&gt;
      &lt;td&gt;0.671703&lt;/td&gt;
      &lt;td&gt;-0.552496&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.143577&lt;/td&gt;
      &lt;td&gt;0.203823&lt;/td&gt;
      &lt;td&gt;-0.060978&lt;/td&gt;
      &lt;td&gt;0.035533&lt;/td&gt;
      &lt;td&gt;0.364947&lt;/td&gt;
      &lt;td&gt;-0.541904&lt;/td&gt;
      &lt;td&gt;0.312770&lt;/td&gt;
      &lt;td&gt;0.109903&lt;/td&gt;
      &lt;td&gt;0.226373&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;residual sugar&lt;/td&gt;
      &lt;td&gt;0.114777&lt;/td&gt;
      &lt;td&gt;0.001918&lt;/td&gt;
      &lt;td&gt;0.143577&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.055610&lt;/td&gt;
      &lt;td&gt;0.187049&lt;/td&gt;
      &lt;td&gt;0.203028&lt;/td&gt;
      &lt;td&gt;0.355283&lt;/td&gt;
      &lt;td&gt;-0.085652&lt;/td&gt;
      &lt;td&gt;0.005527&lt;/td&gt;
      &lt;td&gt;0.042075&lt;/td&gt;
      &lt;td&gt;0.013732&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;chlorides&lt;/td&gt;
      &lt;td&gt;0.093705&lt;/td&gt;
      &lt;td&gt;0.061298&lt;/td&gt;
      &lt;td&gt;0.203823&lt;/td&gt;
      &lt;td&gt;0.055610&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.005562&lt;/td&gt;
      &lt;td&gt;0.047400&lt;/td&gt;
      &lt;td&gt;0.200632&lt;/td&gt;
      &lt;td&gt;-0.265026&lt;/td&gt;
      &lt;td&gt;0.371260&lt;/td&gt;
      &lt;td&gt;-0.221141&lt;/td&gt;
      &lt;td&gt;-0.128907&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;free sulfur dioxide&lt;/td&gt;
      &lt;td&gt;-0.153794&lt;/td&gt;
      &lt;td&gt;-0.010504&lt;/td&gt;
      &lt;td&gt;-0.060978&lt;/td&gt;
      &lt;td&gt;0.187049&lt;/td&gt;
      &lt;td&gt;0.005562&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.667666&lt;/td&gt;
      &lt;td&gt;-0.021946&lt;/td&gt;
      &lt;td&gt;0.070377&lt;/td&gt;
      &lt;td&gt;0.051658&lt;/td&gt;
      &lt;td&gt;-0.069408&lt;/td&gt;
      &lt;td&gt;-0.050656&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;total sulfur dioxide&lt;/td&gt;
      &lt;td&gt;-0.113181&lt;/td&gt;
      &lt;td&gt;0.076470&lt;/td&gt;
      &lt;td&gt;0.035533&lt;/td&gt;
      &lt;td&gt;0.203028&lt;/td&gt;
      &lt;td&gt;0.047400&lt;/td&gt;
      &lt;td&gt;0.667666&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.071269&lt;/td&gt;
      &lt;td&gt;-0.066495&lt;/td&gt;
      &lt;td&gt;0.042947&lt;/td&gt;
      &lt;td&gt;-0.205654&lt;/td&gt;
      &lt;td&gt;-0.185100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;density&lt;/td&gt;
      &lt;td&gt;0.668047&lt;/td&gt;
      &lt;td&gt;0.022026&lt;/td&gt;
      &lt;td&gt;0.364947&lt;/td&gt;
      &lt;td&gt;0.355283&lt;/td&gt;
      &lt;td&gt;0.200632&lt;/td&gt;
      &lt;td&gt;-0.021946&lt;/td&gt;
      &lt;td&gt;0.071269&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;-0.341699&lt;/td&gt;
      &lt;td&gt;0.148506&lt;/td&gt;
      &lt;td&gt;-0.496180&lt;/td&gt;
      &lt;td&gt;-0.174919&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pH&lt;/td&gt;
      &lt;td&gt;-0.682978&lt;/td&gt;
      &lt;td&gt;0.234937&lt;/td&gt;
      &lt;td&gt;-0.541904&lt;/td&gt;
      &lt;td&gt;-0.085652&lt;/td&gt;
      &lt;td&gt;-0.265026&lt;/td&gt;
      &lt;td&gt;0.070377&lt;/td&gt;
      &lt;td&gt;-0.066495&lt;/td&gt;
      &lt;td&gt;-0.341699&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;-0.196648&lt;/td&gt;
      &lt;td&gt;0.205633&lt;/td&gt;
      &lt;td&gt;-0.057731&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;sulphates&lt;/td&gt;
      &lt;td&gt;0.183006&lt;/td&gt;
      &lt;td&gt;-0.260987&lt;/td&gt;
      &lt;td&gt;0.312770&lt;/td&gt;
      &lt;td&gt;0.005527&lt;/td&gt;
      &lt;td&gt;0.371260&lt;/td&gt;
      &lt;td&gt;0.051658&lt;/td&gt;
      &lt;td&gt;0.042947&lt;/td&gt;
      &lt;td&gt;0.148506&lt;/td&gt;
      &lt;td&gt;-0.196648&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.093595&lt;/td&gt;
      &lt;td&gt;0.251397&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;alcohol&lt;/td&gt;
      &lt;td&gt;-0.061668&lt;/td&gt;
      &lt;td&gt;-0.202288&lt;/td&gt;
      &lt;td&gt;0.109903&lt;/td&gt;
      &lt;td&gt;0.042075&lt;/td&gt;
      &lt;td&gt;-0.221141&lt;/td&gt;
      &lt;td&gt;-0.069408&lt;/td&gt;
      &lt;td&gt;-0.205654&lt;/td&gt;
      &lt;td&gt;-0.496180&lt;/td&gt;
      &lt;td&gt;0.205633&lt;/td&gt;
      &lt;td&gt;0.093595&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.476166&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;quality&lt;/td&gt;
      &lt;td&gt;0.124052&lt;/td&gt;
      &lt;td&gt;-0.390558&lt;/td&gt;
      &lt;td&gt;0.226373&lt;/td&gt;
      &lt;td&gt;0.013732&lt;/td&gt;
      &lt;td&gt;-0.128907&lt;/td&gt;
      &lt;td&gt;-0.050656&lt;/td&gt;
      &lt;td&gt;-0.185100&lt;/td&gt;
      &lt;td&gt;-0.174919&lt;/td&gt;
      &lt;td&gt;-0.057731&lt;/td&gt;
      &lt;td&gt;0.251397&lt;/td&gt;
      &lt;td&gt;0.476166&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out correlation heatmap using &#39;seaborn&#39; library
sns.heatmap(df.corr(), cmap = &amp;quot;YlGnBu&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1fad1400&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/image3.png&#34; alt=&#34;This is an image&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;modeling&#34;&gt;Modeling&lt;/h1&gt;
&lt;h2 id=&#34;using-linear-regression&#34;&gt;Using Linear Regression&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create a linear regression model:
model = LinearRegression()

# Train (&amp;quot;fit&amp;quot;) the model:
model = model.fit(df[ [&#39;fixed acidity&#39;, &#39;volatile acidity&#39;, &#39;citric acid&#39;, &#39;residual sugar&#39;, &#39;chlorides&#39;, &#39;free sulfur dioxide&#39;, &#39;total sulfur dioxide&#39;, &#39;density&#39;, &#39;pH&#39;, &#39;sulphates&#39;,&#39;alcohol&#39;] ], df[&#39;quality&#39;] )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out the intercept:
intercept = model.intercept_
intercept

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;21.965208449448177
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# print out the slope (as table):
slope = model.coef_

coeff_df = pd.DataFrame(slope, [&#39;fixed acidity&#39;, &#39;volatile acidity&#39;, &#39;citric acid&#39;, &#39;residual sugar&#39;, &#39;chlorides&#39;, &#39;free sulfur dioxide&#39;, &#39;total sulfur dioxide&#39;, &#39;density&#39;, &#39;pH&#39;, &#39;sulphates&#39;,&#39;alcohol&#39;]  , columns = [&#39;Coefficient&#39;])  
coeff_df
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Coefficient&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;fixed acidity&lt;/td&gt;
      &lt;td&gt;0.024991&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;volatile acidity&lt;/td&gt;
      &lt;td&gt;-1.083590&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;citric acid&lt;/td&gt;
      &lt;td&gt;-0.182564&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;residual sugar&lt;/td&gt;
      &lt;td&gt;0.016331&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;chlorides&lt;/td&gt;
      &lt;td&gt;-1.874225&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;free sulfur dioxide&lt;/td&gt;
      &lt;td&gt;0.004361&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;total sulfur dioxide&lt;/td&gt;
      &lt;td&gt;-0.003265&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;density&lt;/td&gt;
      &lt;td&gt;-17.881164&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pH&lt;/td&gt;
      &lt;td&gt;-0.413653&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;sulphates&lt;/td&gt;
      &lt;td&gt;0.916334&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;alcohol&lt;/td&gt;
      &lt;td&gt;0.276198&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# create prediction using our model
df[&amp;quot;predicted&amp;quot;] = model.predict( df[ [&#39;fixed acidity&#39;, &#39;volatile acidity&#39;, &#39;citric acid&#39;, &#39;residual sugar&#39;, &#39;chlorides&#39;, &#39;free sulfur dioxide&#39;, &#39;total sulfur dioxide&#39;, &#39;density&#39;, &#39;pH&#39;, &#39;sulphates&#39;,&#39;alcohol&#39;] ] )

df[&amp;quot;predicted&amp;quot;] = round(df[&amp;quot;predicted&amp;quot;], 0)
df[&amp;quot;predicted&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0       5.0
1       5.0
2       5.0
3       6.0
4       5.0
       ... 
1594    6.0
1595    6.0
1596    6.0
1597    5.0
1598    6.0
Name: predicted, Length: 1599, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;results&#34;&gt;Results&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h3 id=&#34;relationship-of-ph-and-fixed-acidity&#34;&gt;Relationship of &lt;code&gt;pH&lt;/code&gt; and &lt;code&gt;fixed acidity&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;From the correlation matrix (in EDA section), we can see that &lt;code&gt;pH&lt;/code&gt; and &lt;code&gt;fixed acidity&lt;/code&gt; have the highest correlation with the value of &lt;strong&gt;-0.682978&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create a scatter plot between &#39;pH&#39; (x-axis) and &#39;fixed acidity&#39;(y-axis). 
df.plot.scatter(x = &#39;pH&#39;, y = &#39;fixed acidity&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1a2009fb00&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/image4.png&#34; alt=&#34;This is an image&#34;&gt;&lt;/p&gt;
&lt;p&gt;This negative correlation might be obvious and understandable since&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pH is the measure of acidity/basicity with a scale between 0 (very acid) and 14 (very basic) # information taken from chemistry class&lt;/li&gt;
&lt;li&gt;so the more acidic is a solution, pH value will decrease.&lt;/li&gt;
&lt;li&gt;as indicated in the data description, most wines are acidic and have pH values of 3-4 # in this data (lowest = 2.74 and highest = 4.01) obtained from EDA section.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Therefore, we can conclude that there is a causation between &lt;code&gt;pH&lt;/code&gt; and &lt;code&gt;fixed acidity&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h3 id=&#34;relationship-of-quality-and-alcohol&#34;&gt;Relationship of &lt;code&gt;quality&lt;/code&gt; and &lt;code&gt;alcohol&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;From the correlation matrix (in EDA section), we found out that &lt;code&gt;alcohol&lt;/code&gt; has the highest correlation with our target or response variable &lt;code&gt;quality&lt;/code&gt; with a value of &lt;strong&gt;0.476166&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# visualization using &#39;seaborn&#39; library for scatter plot between &#39;alcohol&#39; and &#39;quality&#39;
sns.set()
sns.relplot(data = df, x = &#39;alcohol&#39;, y = &#39;quality&#39;, kind = &#39;line&#39;, height = 6, aspect = 2, color = &#39;red&#39;);    
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/image5.jpg&#34; alt=&#34;This is an image&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The plot above clearly reflects the positive correlation between &lt;code&gt;quality&lt;/code&gt; and &lt;code&gt;alcohol&lt;/code&gt;. Where an increase in the alcohol level (&lt;strong&gt;&amp;lt;&lt;/strong&gt; 14) &lt;strong&gt;might&lt;/strong&gt; result in a better wine quality.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One important thing to mention is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;This might not be necessarily true&lt;/strong&gt; since there are cases where a higher quality level might result in lower wine quality. (in this dataset, for instance, a wine with 9% alcohol level has a lower quality than wine with 8% alcohol level).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;While there is a positive correlation between &lt;code&gt;quality&lt;/code&gt; and &lt;code&gt;alcohol&lt;/code&gt; their relationship does not indicate causality.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;discussion&#34;&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The predictive ability of our model is very &lt;strong&gt;low&lt;/strong&gt; with an accuracy of only &lt;strong&gt;59.16%&lt;/strong&gt;. This means our model does a really bad job on predicting the wine quality.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This bad results (predictive power) might be due to:
&lt;ul&gt;
&lt;li&gt;Limited predictor variable; in this dataset, we are only given variables that are based on physicochemical tests (lab tests such as alcohol percentage level, pH value, etc.).&lt;/li&gt;
&lt;li&gt;There are many predictor variables that might be more helpful in order to predict the wine quality such as &lt;code&gt;grape type&lt;/code&gt;, &lt;code&gt;wine age&lt;/code&gt;, &lt;code&gt;vineyard location&lt;/code&gt;, and etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# check our model accuracy
(df[&amp;quot;predicted&amp;quot;] == df[&amp;quot;quality&amp;quot;]).mean()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0.5916197623514696
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;solutions-and-recommendations&#34;&gt;Solutions and Recommendations:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Obtain more data (predictor variables and samples) and do another analysis.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Are Sleep Trackers Effective?</title>
      <link>/post/are-sleep-trackers-effective/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/post/are-sleep-trackers-effective/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#methods&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; Methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#results&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#discussion&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;5&lt;/span&gt; Discussion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;6&lt;/span&gt; Appendix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;hr /&gt;
&lt;div id=&#34;abstract&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Abstract&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Personal sleep tracking devices are becoming more and more popular. Statistical learning techniques are used to determine if it is possible to effectively predict time asleep from data that would be available without the aid of a sleep tracker.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Introduction&lt;/h1&gt;
&lt;p&gt;It is without question that sleep is a very important process for both learning and memory. &lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; For optimal learning, sleep, both in quality and quantity, is required before and after learning. Depending on certain demographic factors, there are different sleep prescriptions, but for adults, a minimum of seven hours is needed to avoid impairment. &lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Recently, the link between shift work and cancer has been well established. While more study is needed, there seems to be growing evidence that lack of sleep may play a strong causal role in many cancers. &lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; As the public has become more aware of the importance of sleep, the use of “smart” devices to track sleep has risen. Many sleep trackers provide a wealth of information including not only time asleep, but also details such as time spent in the various stages of sleep. (Light, deep, REM.)&lt;/p&gt;
&lt;p&gt;The effectiveness of these sleep devices is still in question. &lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; While the breadth of data that they make available is interesting, the most important by far is the total time asleep. (Asleep being defined clinically, not by simply being in bed.) The additional data, such as time in REM sleep, is interesting, however it is unclear what the target values should be, and more importantly, how we could affect change in these numbers. In contrast, there is a wealth of advice on how to increase quality and time spent asleep. &lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; If total time asleep is the only data worth tracking, is a smart device actually necessary? Is it possible to estimate time asleep based on simple metrics such as time spent in bed?&lt;/p&gt;
&lt;p&gt;Statistical learning techniques were applied to a four month sample of data from a Fitbit &lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; user. Time spent in bed was used to predict total time asleep. The results indicate that this prediction can be made with a reasonably small amount of error. However, practical and statistical limitations suggest the need for further investigation.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;methods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Methods&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Data&lt;/h2&gt;
&lt;p&gt;The data was accessed via the data export tool provided by Fitbit. &lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; It was collected using a Fitbit Versa 2 by a single subject, a 32 year old adult male living in Ohio and working as a professor. The Fitbit Versa 2 uses both motion and heart rate variability &lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt; to predict when the user is sleeping. The collection dates were a series of consecutive days in autumn of 2018. The two quantities of interest in the data are the time spent asleep and the time spent in bed each time the user sleeps. (A user could sleep more than once a day. For example, a two hour nap in the afternoon.) If the former can be predicted from the latter, the device seems unnecessary. (Time spent in bed could simply be tracked manually by a user. Although, it should be noted that one of the benefits of the devices is the automatic tracking of this quantity, which is probably more accurate than manual human tracking.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; Modeling&lt;/h2&gt;
&lt;p&gt;In order to predict time asleep given time in bed, three modeling techniques were considered: linear models, k-nearest neighbors models, and tree models. No transformations were considered with the linear model. Default tuning parameters were used to train the two non-parametric models. Only time in bed was used as a predictor variable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3&lt;/span&gt; Evaluation&lt;/h2&gt;
&lt;p&gt;To evaluate the ability to predict time asleep with these models, the data was split into estimation, validation, and testing sets. Because of the dependence structure of the data, that is the consecutive nature of the days, the data was split chronologically. That is, the test set is the last 20% of the data chronologically. (And similarly for the validation data.) This is done to evaluate the ability to predict future nights of sleep from past data. Error metrics and graphics are reported using the validation data in the Results section.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Results&lt;/h1&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
model
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
rmse
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Linear
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.444805
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
K-Nearest Neighbors
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
11.692058
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Tree
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15.112509
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-are-sleep-trackers-effective/index_files/figure-html/graphical-results-1.png&#34; width=&#34;1152&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;discussion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;5&lt;/span&gt; Discussion&lt;/h1&gt;
&lt;p&gt;After calculating the Rooted Mean Squared Error (RMSE) which gives us an estimate of the average squared prediction error in the original units used by the response variable for the validation data, we can see that the &lt;strong&gt;linear model&lt;/strong&gt; (without transformation) possess the lowest value of RMSE.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9.1931&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Shown above is the value for our Test RMSE. In our linear model, the test RMSE and our validation RMSE is very similar which means there might be a little to no chance of overfit. Moreover, the plot for our linear model looks reasonable enough. Therefore, the linear model is our best model.&lt;/p&gt;
&lt;p&gt;We are trying to predict the total sleep time based only the past data and one predictor which is very hard if we do not account a seasonal factor that could potentially result in limitations of our analysis. For instance, there might be a day where the observed person is very tired thus, he only spends a very little time in bed (’time_bed’) before he fell asleep. The inability to adjust our analysis to the seasonality effects may lead to false interpretations of the results from the analysis. Therefore, due to the RMSE value and limitations, using sleep tracking devices are still the best way to track our total sleep time even though our prediction is close enough to the actual value.&lt;/p&gt;
&lt;p&gt;Future directions:
We should consider using more variable as our predictor and also put the seasonal factor into account. By doing so we might further increase the accuracy of our predicted values.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;6&lt;/span&gt; Appendix&lt;/h1&gt;
&lt;div id=&#34;data-dictionary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;6.1&lt;/span&gt; Data Dictionary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; - The date and time which the device detected the user has gone to bed due to lack of motion. (But not necessarily started sleep.)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; - The date and time which the device detected that the user is no longer in bed, due to motion.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_asleep&lt;/code&gt; - The total sleep time, in minutes. This is meant to estimate a clinical measure of sleep. (Not simply time in bed.)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_awake&lt;/code&gt; - The time spent in bed, but awake, in minutes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_awake&lt;/code&gt; - The number of times the user “awoke” during their time in bed.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;time_bed&lt;/code&gt; - Duration between &lt;code&gt;start_time&lt;/code&gt; and &lt;code&gt;end_time&lt;/code&gt;. The sum of &lt;code&gt;min_asleep&lt;/code&gt; and &lt;code&gt;min_awake&lt;/code&gt;. In other words, total time in bed, in minutes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_rem&lt;/code&gt; - Total time spent in REM sleep, in minutes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_light&lt;/code&gt; - Total time spent in light sleep, in minutes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_deep&lt;/code&gt; - Total time spent in deep sleep, in minutes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;eda&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;6.2&lt;/span&gt; EDA&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-18-are-sleep-trackers-effective/index_files/figure-html/eda-plots-1.png&#34; width=&#34;1152&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://healthysleep.med.harvard.edu/healthy/matters/benefits-of-sleep/learning-memory&#34;&gt;Harvard Medicine: Sleep, Learning, and Memory&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.cdc.gov/sleep/about_sleep/how_much_sleep.html&#34;&gt;CDC: How Much Sleep Do I Need?&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2954516/&#34;&gt;Shift Work and Cancer, The Evidence and the Challenge&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1586/17434440.2016.1171708&#34;&gt;Consumer sleep tracking devices: a review of mechanisms, validity and utility&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://news.berkeley.edu/2017/10/17/whywesleep/&#34;&gt;Everything you need to know about sleep, but are too tired to ask&lt;/a&gt;&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Fitbit&#34;&gt;Wikipedia: Fitbit&lt;/a&gt;&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;The author would like to note that Fitbit makes it incredibly difficult for users to obtain their own data.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.m.wikipedia.org/wiki/Heart_rate_variability&#34;&gt;Wikipedia: Heart rate variability&lt;/a&gt;&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
